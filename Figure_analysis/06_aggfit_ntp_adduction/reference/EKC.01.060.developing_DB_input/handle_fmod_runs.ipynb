{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import glob\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_log(log_file, sample_name, run0420 = None):\n",
    "    \"\"\"\n",
    "    Extracts information from a ShapeMapper log file.\n",
    "\n",
    "    Parameters:\n",
    "        log_file (str): Path to the ShapeMapper log file.\n",
    "        sample_name (str): Name of the sample to check against the R1 file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains the following elements:\n",
    "            - run_datetime (str): The datetime when the ShapeMapper run started.\n",
    "            - version (str): The version of ShapeMapper used.\n",
    "            - r1_file (str): The R1 file used in the run.\n",
    "            - untreated (int): Indicates if the sample was untreated (1 if untreated, 0 otherwise).\n",
    "            - denatured (int): Indicates if the sample was denatured (1 if denatured, 0 otherwise).\n",
    "            - sample_check (bool): Indicates if the sample name matches the R1 file.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(log_file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # find all lines containing \"Started ShapeMapper\" and get index of most recent one\n",
    "    detect_shapemapper_runs = [i for i, line in enumerate(lines) if 'Started ShapeMapper' in line]\n",
    "    assert len(detect_shapemapper_runs) > 0, 'No ShapeMapper runs detected in log file'\n",
    "\n",
    "    most_recent_run = detect_shapemapper_runs[-1]\n",
    "    lines = lines[most_recent_run:]\n",
    "\n",
    "    # check shapemapper success\n",
    "    run_completed = [i for i, line in enumerate(lines) if ('ShapeMapper run completed' in line) or ('ShapeMapper run successfully completed' in line)]\n",
    "    if len(run_completed) == 0:\n",
    "        print(f'ShapeMapper run not completed successfully in log file: {log_file}')\n",
    "        return None\n",
    "\n",
    "    #print(log_file)\n",
    "    # extract date and version from:  \"Started ShapeMapper v2.2.0 at 2023-04-22 17:19:59\"\n",
    "    version_date_line = lines[0]\n",
    "    run_datetime = version_date_line.split(' at ')[1].rstrip()\n",
    "    version = version_date_line.split(' ')[2]\n",
    "    run_args = lines[2]\n",
    "    assert 'args: ' in run_args, 'args line not found in log file'\n",
    "    \n",
    "    # get index of 'modified'\n",
    "    modified_index = run_args.split(' --').index('modified')\n",
    "    assert modified_index > 0, 'modified not found in run_args'\n",
    "\n",
    "    # extract R1 file\n",
    "    r1_file = run_args.split(' --')[modified_index + 1].split(' ')[-1]\n",
    "    assert (r1_file is not None) or (r1_file == ''), 'R1 file not found in run_args'\n",
    "\n",
    "    untreated = 0\n",
    "    denatured = 0\n",
    "    # check if untreated sample provided\n",
    "    if 'untreated' in run_args.split(' --'):\n",
    "        untreated_index = run_args.split(' --').index('untreated')\n",
    "        untreated_r1_file = run_args.split(' --')[untreated_index + 1].split(' ')[-1]\n",
    "        assert (untreated_r1_file is not None) or (untreated_r1_file == ''), 'R1 file not found in run_args'\n",
    "        untreated = untreated_r1_file\n",
    "    elif 'denatured' in run_args.split(' --'):\n",
    "        denatured_index = run_args.split(' --').index('denatured')\n",
    "        den_r1_file = run_args.split(' --')[denatured_index + 1].split(' ')[-1]\n",
    "        assert (den_r1_file is not None) or (den_r1_file == ''), 'R1 file not found in run_args'\n",
    "        denatured = den_r1_file\n",
    "\n",
    "    # confirm sample_name matches r1_file\n",
    "    # remove .fastq.gz from both if they exist\n",
    "    if len(r1_file.split('/')) > 2:\n",
    "        r1_file = r1_file.split('/')[-1]\n",
    "        r1_file_check = r1_file.replace('...', '')\n",
    "        sample_name_check = sample_name[:len(r1_file_check)]\n",
    "        sample_check = (sample_name_check == r1_file_check)\n",
    "        return run_datetime, run_args, version, r1_file, untreated, denatured, sample_check\n",
    "    if r1_file.endswith('.fastq.gz'):\n",
    "        r1_file_check = r1_file[:-9]\n",
    "    elif r1_file.endswith('.fastq'):\n",
    "        r1_file_check = r1_file[:-6]\n",
    "    else:\n",
    "        r1_file_check = r1_file\n",
    "    if sample_name.endswith('.fastq.gz'):\n",
    "        sample_name_check = sample_name[:-9]\n",
    "    elif sample_name.endswith('.fastq'):\n",
    "        sample_name_check = sample_name[:-6]\n",
    "    else:\n",
    "        sample_name_check = sample_name\n",
    "    if r1_file.startswith('./'):\n",
    "        r1_file_check = r1_file_check[2:]\n",
    "    if sample_name_check.startswith('YYYR'):\n",
    "        r1_file_check = r1_file_check[5:]\n",
    "        sample_name_check = sample_name_check[5:]\n",
    "    elif sample_name_check.startswith('etOH'):\n",
    "        #DMS-150-WTII_S8_L001_R1_001 etOH-150-WTII_S16_L001_R1_001\n",
    "        r1_file_check = '-'.join(r1_file_check.split('_')[0].split('-')[1:])\n",
    "        sample_name_check = '-'.join(sample_name_check.split('_')[0].split('-')[1:])\n",
    "\n",
    "    sample_check = (sample_name_check == r1_file_check)\n",
    "\n",
    "    # override mistaken r1 file name\n",
    "    if 'WT-33c-b-6' in r1_file_check:\n",
    "        sample_check = True\n",
    "        return run_datetime, run_args, version, r1_file, untreated, denatured, sample_check\n",
    "\n",
    "    if sample_check == False:\n",
    "        # try removing all underscores and compare again\n",
    "        r1_file_check = r1_file_check.replace('_', '')\n",
    "        sample_name_check = sample_name_check.replace('_', '')\n",
    "        sample_check = (sample_name_check == r1_file_check)\n",
    "        if sample_check == False:\n",
    "            print('upper', r1_file_check, sample_name_check)\n",
    "\n",
    "    if run0420:\n",
    "        name_index = run_args.split(' --')[1]\n",
    "        assert 'name' in name_index, 'name not found in run_args'\n",
    "        name_check = name_index.split(' ')[-1]\n",
    "        sample_check = (name_check in sample_name) or (r1_file_check == sample_name_check)\n",
    "        if sample_check:\n",
    "            print('Rechecking on name successful')\n",
    "        else:\n",
    "            print('lower', r1_file_check, sample_name_check)\n",
    "\n",
    "    return run_datetime, run_args, version, r1_file, untreated, denatured, sample_check\n",
    "\n",
    "def fetch_s_id(db_file, sample_name):\n",
    "    \"\"\"\n",
    "    Fetches the ID of a sample from the sequencing_samples table.\n",
    "\n",
    "    Parameters:\n",
    "        db_file (str): Path to the database file.\n",
    "        sample_name (str): Name of the sample to fetch the ID for.\n",
    "\n",
    "    Returns:\n",
    "        int: The ID of the sample.\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_file)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT id FROM sequencing_samples WHERE sample_name = ?', (sample_name,))\n",
    "    result = c.fetchall()  # Fetch only one row\n",
    "    conn.close()\n",
    "\n",
    "    if result is None:\n",
    "        raise ValueError(f\"No sample found with name: {sample_name}\")\n",
    "    elif len(result) > 1:\n",
    "        raise ValueError(f\"Multiple samples found with name: {sample_name}\")\n",
    "    else:\n",
    "        print(result)\n",
    "        return result[0][0]  # Extract ID from tuple\n",
    "\n",
    "def get_max_id(db_file, table, id_col):\n",
    "    \"\"\"\n",
    "        Fetches the maximum ID from a specified table and column.\n",
    "\n",
    "        Parameters:\n",
    "            db_file (str): Path to the database file.\n",
    "            table (str): Name of the table to query.\n",
    "            id_col (str): Name of the ID column to find the maximum value.\n",
    "\n",
    "        Returns:\n",
    "            int: The maximum ID value plus one, or 1 if the table is empty.\n",
    "        \"\"\"\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"SELECT MAX({id_col}) FROM {table}\")\n",
    "    max_id = c.fetchone()[0]\n",
    "    return max_id + 1 if max_id else 1\n",
    "\n",
    "def fetch_construct_seq(db_file, s_id):\n",
    "    \"\"\"\n",
    "    Fetches the construct sequence for a given sample ID.\n",
    "\n",
    "    Parameters:\n",
    "        db_file (str): Path to the database file.\n",
    "        s_id (int): Sample ID to fetch the construct sequence for.\n",
    "\n",
    "    Returns:\n",
    "        str: The construct sequence with T's converted to U's.\n",
    "    \"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT construct_id FROM probing_reactions WHERE s_id = ?', (s_id,))\n",
    "    construct_id = c.fetchone()[0]\n",
    "    c.execute('SELECT sequence FROM constructs WHERE id = ?', (construct_id,))\n",
    "    construct_seq = c.fetchone()[0]\n",
    "    dict_convertTU = {'T': 'U', 't': 'u'}\n",
    "    construct_seq = ''.join([dict_convertTU.get(base, base) for base in construct_seq])\n",
    "    conn.close()\n",
    "    return construct_seq\n",
    "\n",
    "def fetch_rxn_id(db_file, s_id):\n",
    "    \"\"\"\n",
    "    Fetches the reaction ID for a given sample ID.\n",
    "\n",
    "    Parameters:\n",
    "        db_file (str): Path to the database file.\n",
    "        s_id (int): Sample ID to fetch the reaction ID for.\n",
    "\n",
    "    Returns:\n",
    "        int: The reaction ID.\n",
    "    \"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT id, treated FROM probing_reactions WHERE s_id = ?', (s_id,))\n",
    "    result = c.fetchone()\n",
    "    conn.close()\n",
    "    \n",
    "    rxn_id = result[0]\n",
    "    treated = result[1]\n",
    "    return rxn_id, treated\n",
    "\n",
    "def fetch_nt_ids(db_file, s_id):\n",
    "    \"\"\"\n",
    "    Fetches the nucleotide IDs and sequence for a given sample ID.\n",
    "\n",
    "    Parameters:\n",
    "        db_file (str): Path to the database file.\n",
    "        s_id (int): Sample ID to fetch the nucleotide IDs and sequence for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing a list of nucleotide IDs and the nucleotide sequence with T's converted to U's.\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_file)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT construct_id FROM probing_reactions WHERE s_id = ?', (s_id,))\n",
    "    construct_id = c.fetchone()[0]\n",
    "    c.execute('SELECT id, base FROM nucleotides WHERE construct_id = ?', (construct_id,))\n",
    "    selected_nts = sorted(c.fetchall())\n",
    "    conn.close()\n",
    "\n",
    "    nt_ids = [nt[0] for nt in selected_nts]\n",
    "    nt_seq = ''.join([nt[1] for nt in selected_nts])\n",
    "    dict_convertTU = {'T': 'U', 't': 'u'}\n",
    "    nt_seq = ''.join([dict_convertTU.get(base, base) for base in nt_seq])\n",
    "    return nt_ids, nt_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct fmod_calc_run entry\n",
    "\n",
    "def construct_fmod_calc_run(sample_name, fmod_dir, db_file, run0420 = None):\n",
    "\n",
    "    run = glob.glob(f'/projects/b1044/Computational_Output/EKC/{fmod_dir}/*shapemapper_log*')[0]\n",
    "    run_datetime, run_args, version, r1_file, untreated, denatured, sample_check = extract_info_from_log(run, sample_name, run0420)\n",
    "    s_id = fetch_s_id(db_file, sample_name)\n",
    "\n",
    "    # get potential fmod_calc id but do not add until fmod vals are good\n",
    "\n",
    "    # Tentative fmod_calc id (pending fmod_vals check)\n",
    "    fmod_calc_id = get_max_id(db_file, 'fmod_calc_runs', 'id')\n",
    "\n",
    "    profile_txt = glob.glob(f'/projects/b1044/Computational_Output/EKC/{fmod_dir}/**/*_profile.txt', recursive=True)\n",
    "    # exclude shapemapper_temp\n",
    "    profile_txt = [x for x in profile_txt if 'shapemapper_temp' not in x]\n",
    "    # choose profile with \"reanalyzed\"\n",
    "    if len(profile_txt) > 1:\n",
    "        profile_txt = [x for x in profile_txt if 'reanalyzed' in x]\n",
    "        #print(fmod_dir, profile_txt)\n",
    "    assert len(profile_txt) == 1, 'Multiple or no profile.txt files found'\n",
    "    profile_txt = profile_txt[0]\n",
    "    \n",
    "    \n",
    "    # process GAmodrate\n",
    "    profile_txtga = glob.glob(f'/projects/b1044/Computational_Output/EKC/{fmod_dir}/**/*_profile.txtga', recursive=True)\n",
    "\n",
    "    # exclude shapemapper_temp\n",
    "    profile_txtga = [x for x in profile_txtga if 'shapemapper_temp' not in x]\n",
    "    # choose profile with \"reanalyzed\"\n",
    "    if len(profile_txtga) > 1:\n",
    "        profile_txtga = [x for x in profile_txtga if 'reanalyzed' in x]\n",
    "        #print(fmod_dir, profile_txt)\n",
    "    elif len(profile_txtga) == 0:\n",
    "        profile_txtga = None\n",
    "    else:\n",
    "        profile_txtga = profile_txtga[0]\n",
    "\n",
    "    # handle untreated or denatured\n",
    "    rxn_id, rxn_treated = fetch_rxn_id(db_file, s_id)\n",
    "\n",
    "    use_untreated_calc = False\n",
    "\n",
    "    if (untreated != 0) & (rxn_treated == 0):\n",
    "        r1_file = untreated\n",
    "        use_untreated_calc = True\n",
    "    elif (denatured != 0) & (rxn_treated == 1):\n",
    "        r1_file = denatured\n",
    "\n",
    "    return run_datetime, run_args, version, use_untreated_calc, r1_file, sample_check, s_id, fmod_calc_id, profile_txt, profile_txtga\n",
    "\n",
    "def construct_fmod_vals(profile_txt, db_file, s_id, fmod_calc_id, use_untreated_calc):\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(profile_txt, sep='\\t')\n",
    "    seq_from_profile = ''.join(df['Sequence'].values)\n",
    "\n",
    "    construct_seq = fetch_construct_seq(db_file, s_id)\n",
    "    assert construct_seq.upper() == seq_from_profile.upper(), 'Construct sequence does not match profile.txt sequence'\n",
    "\n",
    "    nt_ids, nt_seq = fetch_nt_ids(db_file, s_id)\n",
    "\n",
    "    assert nt_seq.upper() == seq_from_profile.upper(), 'Nt sequence does not match profile.txt sequence'\n",
    "\n",
    "    rxn_id, rxn_treated = fetch_rxn_id(db_file, s_id)\n",
    "\n",
    "    if use_untreated_calc:\n",
    "        #print('using untreated')\n",
    "        fmod_vals = df['Untreated_rate'].values\n",
    "        read_depths = df['Untreated_read_depth'].values\n",
    "    else:\n",
    "        fmod_vals = df['Modified_rate'].values\n",
    "        read_depths = df['Modified_read_depth'].values\n",
    "\n",
    "    fmod_vals_df = pd.DataFrame({'nt_id': nt_ids, 'fmod_calc_run_id': fmod_calc_id, 'fmod_val': fmod_vals, 'valtype': 'modrate', 'read_depth': read_depths, 'rxn_id': rxn_id})\n",
    "    return fmod_vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmod_calc_runs_2/000000004589\n",
      "fmod_calc_runs_2/000000004589\n",
      "042_P4P6_WT_nobc_0mMMgMRTpH9_tp6_p\n",
      "[(1101,)]\n"
     ]
    }
   ],
   "source": [
    "samples = pd.read_csv('/projects/b1044/Computational_Output/EKC/EKC.01_SHAPE_standardization/EKC.01.060.developing_DB_input/samples_import.csv')\n",
    "\n",
    "skipped = []\n",
    "\n",
    "i = 112\n",
    "# check if sample_name column has not repeats\n",
    "fmod_dir = samples[samples['RT'] == 'MRT']['fmod_runs'].values[i]\n",
    "sample_name = samples[samples['RT'] == 'MRT']['sample_name'].values[i]\n",
    "\n",
    "i = 5\n",
    "# check if sample_name column has not repeats\n",
    "fmod_dir = samples[samples['sequencing_run'] == 23]['fmod_runs'].values[i]\n",
    "sample_name = samples[samples['sequencing_run'] == 23]['sample_name'].values[i]\n",
    "\n",
    "i = 5\n",
    "# check if sample_name column has not repeats\n",
    "fmod_dir = samples[samples['RT'] == 'MRTpH9']['fmod_runs'].values[i]\n",
    "sample_name = samples[samples['RT'] == 'MRTpH9']['sample_name'].values[i]\n",
    "\n",
    "# i = 5\n",
    "# # check if sample_name column has not repeats\n",
    "# fmod_dir = samples[samples['done_by'] == 'RB']['fmod_runs'].values[i]\n",
    "# sample_name = samples[samples['done_by'] == 'RB']['sample_name'].values[i]\n",
    "\n",
    "# get text inside single quote '\n",
    "print(fmod_dir)\n",
    "if \"'\" in fmod_dir:\n",
    "    fmod_dir = fmod_dir.split(\"'\")[1]\n",
    "print(fmod_dir)\n",
    "print(sample_name)\n",
    "db_file = '/projects/b1044/Computational_Output/EKC/EKC.01_SHAPE_standardization/EKC.01.060.developing_DB_input/new.db'\n",
    "\n",
    "try:\n",
    "    run_datetime, run_args, version, use_untreated_calc, r1_file, sample_check, s_id, fmod_calc_id, profile_txt, profile_txtga = construct_fmod_calc_run(sample_name, fmod_dir, db_file, True)\n",
    "except:\n",
    "    print('Error in log file, skipping...')\n",
    "\n",
    "sample_check = True\n",
    "if sample_check:\n",
    "    fmod_vals_df = construct_fmod_vals(profile_txt, db_file, s_id, fmod_calc_id, use_untreated_calc)\n",
    "    \n",
    "    if profile_txtga is not None:\n",
    "        fmod_vals_df_ga = construct_fmod_vals(profile_txtga, db_file, s_id, fmod_calc_id, use_untreated_calc)\n",
    "        fmod_vals_df_ga['valtype'] = 'GAmodrate'\n",
    "        fmod_vals_df = pd.concat([fmod_vals_df, fmod_vals_df_ga])\n",
    "else:\n",
    "    print('Sample name does not match R1 file, skipping...')\n",
    "    skipped.append(i)\n",
    "\n",
    "# Append fmod_calc_run fmod_vals to db\n",
    "# conn = sqlite3.connect(db_file)\n",
    "# c = conn.cursor()\n",
    "# c.execute('INSERT INTO fmod_calc_runs (id, s_id, run_datetime, version, r1_file) VALUES (?, ?, ?, ?, ?, ?, ?, ?)', (fmod_calc_id, s_id, run_datetime, version, r1_file))\n",
    "# fmod_vals_df.to_sql('fmod_vals', conn, if_exists='append', index=False)\n",
    "# conn.commit()\n",
    "# conn.close()\n",
    "\n",
    "#fmod_vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(25,)]\n",
      "[(26,)]\n",
      "[(27,)]\n",
      "[(28,)]\n",
      "[(29,)]\n",
      "[(30,)]\n",
      "[(31,)]\n",
      "[(32,)]\n",
      "[(33,)]\n",
      "[(34,)]\n",
      "[(35,)]\n",
      "[(36,)]\n",
      "[(37,)]\n",
      "[(38,)]\n",
      "[(65,)]\n",
      "[(66,)]\n",
      "[(67,)]\n",
      "[(68,)]\n",
      "[(69,)]\n",
      "[(70,)]\n",
      "[(71,)]\n",
      "[(72,)]\n",
      "[(73,)]\n",
      "[(74,)]\n",
      "[(75,)]\n",
      "[(76,)]\n",
      "[(77,)]\n",
      "[(78,)]\n",
      "[(79,)]\n",
      "[(80,)]\n",
      "[(105,)]\n",
      "[(106,)]\n",
      "[(107,)]\n",
      "[(108,)]\n",
      "[(109,)]\n",
      "[(110,)]\n",
      "[(111,)]\n",
      "[(112,)]\n",
      "[(113,)]\n",
      "[(114,)]\n",
      "[(115,)]\n",
      "[(116,)]\n",
      "[(117,)]\n",
      "[(118,)]\n",
      "[(119,)]\n",
      "[(120,)]\n",
      "[(121,)]\n",
      "[(122,)]\n",
      "[(123,)]\n",
      "[(124,)]\n",
      "[(125,)]\n",
      "[(126,)]\n",
      "[(127,)]\n",
      "[(128,)]\n",
      "[(129,)]\n",
      "[(130,)]\n",
      "[(131,)]\n",
      "[(132,)]\n",
      "[(133,)]\n",
      "[(134,)]\n",
      "[(135,)]\n",
      "[(136,)]\n",
      "[(162,)]\n",
      "[(163,)]\n",
      "[(164,)]\n",
      "[(165,)]\n",
      "[(166,)]\n",
      "[(167,)]\n",
      "[(168,)]\n",
      "[(169,)]\n",
      "[(170,)]\n",
      "[(171,)]\n",
      "[(172,)]\n",
      "[(173,)]\n",
      "[(174,)]\n",
      "[(175,)]\n",
      "[(176,)]\n",
      "[(177,)]\n",
      "[(178,)]\n",
      "[(179,)]\n",
      "[(180,)]\n",
      "[(181,)]\n",
      "[(182,)]\n",
      "[(183,)]\n",
      "[(184,)]\n",
      "[(185,)]\n",
      "[(186,)]\n",
      "[(187,)]\n",
      "[(188,)]\n",
      "[(189,)]\n",
      "[(190,)]\n",
      "[(191,)]\n",
      "[(192,)]\n",
      "[(193,)]\n",
      "[(194,)]\n",
      "[(195,)]\n",
      "[(196,)]\n",
      "[(197,)]\n",
      "[(198,)]\n",
      "[(199,)]\n",
      "[(200,)]\n",
      "[(201,)]\n",
      "[(202,)]\n",
      "[(203,)]\n",
      "[(204,)]\n",
      "[(205,)]\n",
      "[(206,)]\n",
      "[(207,)]\n",
      "[(208,)]\n",
      "[(209,)]\n",
      "upper RRRYRRRY-001-EKC-fourUnew-WT-70C-dms-MaP-1S1L001R1001 RRRY001-EKC-fourUnew-WT-70C-dms-MaP-1S1L001R1001\n",
      "Rechecking on name successful\n",
      "[(234,)]\n",
      "upper RRRY-001-EKC-fourUnew-WT-70C-dms-MaP-1S1L001R1001 001-EKC-fourUnew-WT-70C-dms-MaP-1S1L001R1001\n",
      "Rechecking on name successful\n",
      "[(235,)]\n",
      "upper RRRYRRRY-003-EKC-fourUnew-WT-70C-dms-MaP-3S3L001R1001 RRRY002-EKC-fourUnew-WT-70C-dms-MaP-2S2L001R1001\n",
      "Rechecking on name successful\n",
      "[(236,)]\n",
      "upper RRRY-003-EKC-fourUnew-WT-70C-dms-MaP-3S3L001R1001 002-EKC-fourUnew-WT-70C-dms-MaP-2S2L001R1001\n",
      "Rechecking on name successful\n",
      "[(237,)]\n",
      "upper RRRYRRRY-005-EKC-fourUnew-WT-70C-dms-MaP-5S5L001R1001 RRRY003-EKC-fourUnew-WT-70C-dms-MaP-3S3L001R1001\n",
      "Rechecking on name successful\n",
      "[(238,)]\n",
      "upper RRRY-005-EKC-fourUnew-WT-70C-dms-MaP-5S5L001R1001 003-EKC-fourUnew-WT-70C-dms-MaP-3S3L001R1001\n",
      "Rechecking on name successful\n",
      "[(239,)]\n",
      "upper RRRYYYYR-001-EKC-fourUnew-WT-70C-dms-MaP-1S1L001R1001 RRRY004-EKC-fourUnew-WT-70C-dms-MaP-4S4L001R1001\n",
      "Rechecking on name successful\n",
      "[(240,)]\n",
      "upper YYYR-001-EKC-fourUnew-WT-70C-dms-MaP-1S1L001R1001 004-EKC-fourUnew-WT-70C-dms-MaP-4S4L001R1001\n",
      "Rechecking on name successful\n",
      "[(241,)]\n",
      "upper RRRYYYYR-003-EKC-fourUnew-WT-70C-dms-MaP-3S3L001R1001 RRRY005-EKC-fourUnew-WT-70C-dms-MaP-5S5L001R1001\n",
      "Rechecking on name successful\n",
      "[(242,)]\n",
      "upper YYYR-003-EKC-fourUnew-WT-70C-dms-MaP-3S3L001R1001 005-EKC-fourUnew-WT-70C-dms-MaP-5S5L001R1001\n",
      "Rechecking on name successful\n",
      "[(243,)]\n",
      "upper RRRYYYYR-005-EKC-fourUnew-WT-70C-dms-MaP-5S5L001R1001 RRRY006-EKC-fourUnew-WT-70C-dms-MaP-6S6L001R1001\n",
      "Rechecking on name successful\n",
      "[(244,)]\n",
      "upper YYYR-005-EKC-fourUnew-WT-70C-dms-MaP-5S5L001R1001 006-EKC-fourUnew-WT-70C-dms-MaP-6S6L001R1001\n",
      "Rechecking on name successful\n",
      "[(245,)]\n",
      "upper RRRYRRRY-007-EKC-fourUnew-WT-75C-dms-MaP-1S7L001R1001 RRRY007-EKC-fourUnew-WT-75C-dms-MaP-1S7L001R1001\n",
      "Rechecking on name successful\n",
      "[(246,)]\n",
      "upper RRRY-007-EKC-fourUnew-WT-75C-dms-MaP-1S7L001R1001 007-EKC-fourUnew-WT-75C-dms-MaP-1S7L001R1001\n",
      "Rechecking on name successful\n",
      "[(247,)]\n",
      "upper RRRYRRRY-009-EKC-fourUnew-WT-75C-dms-MaP-3S9L001R1001 RRRY008-EKC-fourUnew-WT-75C-dms-MaP-2S8L001R1001\n",
      "Rechecking on name successful\n",
      "[(248,)]\n",
      "upper RRRY-009-EKC-fourUnew-WT-75C-dms-MaP-3S9L001R1001 008-EKC-fourUnew-WT-75C-dms-MaP-2S8L001R1001\n",
      "Rechecking on name successful\n",
      "[(249,)]\n",
      "upper RRRYRRRY-011-EKC-fourUnew-WT-75C-dms-MaP-5S11L001R1001 RRRY009-EKC-fourUnew-WT-75C-dms-MaP-3S9L001R1001\n",
      "Rechecking on name successful\n",
      "[(250,)]\n",
      "upper RRRY-011-EKC-fourUnew-WT-75C-dms-MaP-5S11L001R1001 009-EKC-fourUnew-WT-75C-dms-MaP-3S9L001R1001\n",
      "Rechecking on name successful\n",
      "[(251,)]\n",
      "upper RRRYYYYR-007-EKC-fourUnew-WT-75C-dms-MaP-1S7L001R1001 RRRY010-EKC-fourUnew-WT-75C-dms-MaP-4S10L001R1001\n",
      "Rechecking on name successful\n",
      "[(252,)]\n",
      "upper YYYR-007-EKC-fourUnew-WT-75C-dms-MaP-1S7L001R1001 010-EKC-fourUnew-WT-75C-dms-MaP-4S10L001R1001\n",
      "Rechecking on name successful\n",
      "[(253,)]\n",
      "upper RRRYYYYR-009-EKC-fourUnew-WT-75C-dms-MaP-3S9L001R1001 RRRY011-EKC-fourUnew-WT-75C-dms-MaP-5S11L001R1001\n",
      "Rechecking on name successful\n",
      "[(254,)]\n",
      "upper YYYR-009-EKC-fourUnew-WT-75C-dms-MaP-3S9L001R1001 011-EKC-fourUnew-WT-75C-dms-MaP-5S11L001R1001\n",
      "Rechecking on name successful\n",
      "[(255,)]\n",
      "upper RRRYYYYR-011-EKC-fourUnew-WT-75C-dms-MaP-5S11L001R1001 RRRY012-EKC-fourUnew-WT-75C-dms-MaP-6S12L001R1001\n",
      "Rechecking on name successful\n",
      "[(256,)]\n",
      "upper YYYR-011-EKC-fourUnew-WT-75C-dms-MaP-5S11L001R1001 012-EKC-fourUnew-WT-75C-dms-MaP-6S12L001R1001\n",
      "Rechecking on name successful\n",
      "[(257,)]\n",
      "upper RRRYRRRY-013-EKC-fourUnew-WT-80C-dms-MaP-1S13L001R1001 RRRY013-EKC-fourUnew-WT-80C-dms-MaP-1S13L001R1001\n",
      "Rechecking on name successful\n",
      "[(258,)]\n",
      "upper RRRY-013-EKC-fourUnew-WT-80C-dms-MaP-1S13L001R1001 013-EKC-fourUnew-WT-80C-dms-MaP-1S13L001R1001\n",
      "Rechecking on name successful\n",
      "[(259,)]\n",
      "upper RRRYRRRY-015-EKC-fourUnew-WT-80C-dms-MaP-3S15L001R1001 RRRY014-EKC-fourUnew-WT-80C-dms-MaP-2S14L001R1001\n",
      "Rechecking on name successful\n",
      "[(260,)]\n",
      "upper RRRY-015-EKC-fourUnew-WT-80C-dms-MaP-3S15L001R1001 014-EKC-fourUnew-WT-80C-dms-MaP-2S14L001R1001\n",
      "Rechecking on name successful\n",
      "[(261,)]\n",
      "upper RRRYRRRY-017-EKC-fourUnew-WT-80C-dms-MaP-5S17L001R1001 RRRY015-EKC-fourUnew-WT-80C-dms-MaP-3S15L001R1001\n",
      "Rechecking on name successful\n",
      "[(262,)]\n",
      "upper RRRY-017-EKC-fourUnew-WT-80C-dms-MaP-5S17L001R1001 015-EKC-fourUnew-WT-80C-dms-MaP-3S15L001R1001\n",
      "Rechecking on name successful\n",
      "[(263,)]\n",
      "upper RRRYYYYR-013-EKC-fourUnew-WT-80C-dms-MaP-1S13L001R1001 RRRY016-EKC-fourUnew-WT-80C-dms-MaP-4S16L001R1001\n",
      "Rechecking on name successful\n",
      "[(264,)]\n",
      "upper YYYR-013-EKC-fourUnew-WT-80C-dms-MaP-1S13L001R1001 016-EKC-fourUnew-WT-80C-dms-MaP-4S16L001R1001\n",
      "Rechecking on name successful\n",
      "[(265,)]\n",
      "upper RRRYYYYR-015-EKC-fourUnew-WT-80C-dms-MaP-3S15L001R1001 RRRY017-EKC-fourUnew-WT-80C-dms-MaP-5S17L001R1001\n",
      "Rechecking on name successful\n",
      "[(266,)]\n",
      "upper YYYR-015-EKC-fourUnew-WT-80C-dms-MaP-3S15L001R1001 017-EKC-fourUnew-WT-80C-dms-MaP-5S17L001R1001\n",
      "Rechecking on name successful\n",
      "[(267,)]\n",
      "upper RRRYYYYR-017-EKC-fourUnew-WT-80C-dms-MaP-5S17L001R1001 RRRY018-EKC-fourUnew-WT-80C-dms-MaP-6S18L001R1001\n",
      "Rechecking on name successful\n",
      "[(268,)]\n",
      "upper YYYR-017-EKC-fourUnew-WT-80C-dms-MaP-5S17L001R1001 018-EKC-fourUnew-WT-80C-dms-MaP-6S18L001R1001\n",
      "Rechecking on name successful\n",
      "[(269,)]\n",
      "upper RRRYRRRY-019-EKC-fourUnew-WT-85C-dms-MaP-1S19L001R1001 RRRY019-EKC-fourUnew-WT-85C-dms-MaP-1S19L001R1001\n",
      "Rechecking on name successful\n",
      "[(270,)]\n",
      "upper RRRY-019-EKC-fourUnew-WT-85C-dms-MaP-1S19L001R1001 019-EKC-fourUnew-WT-85C-dms-MaP-1S19L001R1001\n",
      "Rechecking on name successful\n",
      "[(271,)]\n",
      "upper RRRYRRRY-021-EKC-fourUnew-WT-85C-dms-MaP-3S21L001R1001 RRRY020-EKC-fourUnew-WT-85C-dms-MaP-2S20L001R1001\n",
      "Rechecking on name successful\n",
      "[(272,)]\n",
      "upper RRRY-021-EKC-fourUnew-WT-85C-dms-MaP-3S21L001R1001 020-EKC-fourUnew-WT-85C-dms-MaP-2S20L001R1001\n",
      "Rechecking on name successful\n",
      "[(273,)]\n",
      "upper RRRYRRRY-023-EKC-fourUnew-WT-85C-dms-MaP-5S23L001R1001 RRRY021-EKC-fourUnew-WT-85C-dms-MaP-3S21L001R1001\n",
      "Rechecking on name successful\n",
      "[(274,)]\n",
      "upper RRRY-023-EKC-fourUnew-WT-85C-dms-MaP-5S23L001R1001 021-EKC-fourUnew-WT-85C-dms-MaP-3S21L001R1001\n",
      "Rechecking on name successful\n",
      "[(275,)]\n",
      "upper RRRYYYYR-019-EKC-fourUnew-WT-85C-dms-MaP-1S19L001R1001 RRRY022-EKC-fourUnew-WT-85C-dms-MaP-4S22L001R1001\n",
      "Rechecking on name successful\n",
      "[(276,)]\n",
      "upper YYYR-019-EKC-fourUnew-WT-85C-dms-MaP-1S19L001R1001 022-EKC-fourUnew-WT-85C-dms-MaP-4S22L001R1001\n",
      "Rechecking on name successful\n",
      "[(277,)]\n",
      "upper RRRYYYYR-021-EKC-fourUnew-WT-85C-dms-MaP-3S21L001R1001 RRRY023-EKC-fourUnew-WT-85C-dms-MaP-5S23L001R1001\n",
      "Rechecking on name successful\n",
      "[(278,)]\n",
      "upper YYYR-021-EKC-fourUnew-WT-85C-dms-MaP-3S21L001R1001 023-EKC-fourUnew-WT-85C-dms-MaP-5S23L001R1001\n",
      "Rechecking on name successful\n",
      "[(279,)]\n",
      "upper RRRYYYYR-023-EKC-fourUnew-WT-85C-dms-MaP-5S23L001R1001 RRRY024-EKC-fourUnew-WT-85C-dms-MaP-6S24L001R1001\n",
      "Rechecking on name successful\n",
      "[(280,)]\n",
      "upper YYYR-023-EKC-fourUnew-WT-85C-dms-MaP-5S23L001R1001 024-EKC-fourUnew-WT-85C-dms-MaP-6S24L001R1001\n",
      "Rechecking on name successful\n",
      "[(281,)]\n",
      "[(306,)]\n",
      "[(307,)]\n",
      "[(308,)]\n",
      "[(309,)]\n",
      "[(310,)]\n",
      "[(311,)]\n",
      "[(312,)]\n",
      "[(313,)]\n",
      "[(314,)]\n",
      "[(315,)]\n",
      "[(316,)]\n",
      "[(317,)]\n",
      "[(318,)]\n",
      "[(320,)]\n",
      "[(321,)]\n",
      "[(322,)]\n",
      "[(323,)]\n",
      "[(324,)]\n",
      "[(325,)]\n",
      "[(326,)]\n",
      "[(327,)]\n",
      "[(328,)]\n",
      "[(329,)]\n",
      "[(330,)]\n",
      "[(331,)]\n",
      "[(332,)]\n",
      "[(333,)]\n",
      "[(334,)]\n",
      "[(335,)]\n",
      "[(336,)]\n",
      "[(337,)]\n",
      "[(338,)]\n",
      "[(339,)]\n",
      "[(340,)]\n",
      "[(341,)]\n",
      "[(342,)]\n",
      "[(343,)]\n",
      "[(344,)]\n",
      "[(345,)]\n",
      "[(346,)]\n",
      "[(347,)]\n",
      "[(348,)]\n",
      "[(349,)]\n",
      "[(350,)]\n",
      "[(351,)]\n",
      "[(352,)]\n",
      "[(353,)]\n",
      "[(354,)]\n",
      "[(355,)]\n",
      "[(356,)]\n",
      "[(357,)]\n",
      "[(358,)]\n",
      "[(359,)]\n",
      "[(360,)]\n",
      "[(361,)]\n",
      "[(362,)]\n",
      "[(363,)]\n",
      "[(364,)]\n",
      "[(365,)]\n",
      "[(366,)]\n",
      "[(367,)]\n",
      "[(368,)]\n",
      "[(369,)]\n",
      "[(370,)]\n",
      "[(371,)]\n",
      "[(372,)]\n",
      "[(373,)]\n",
      "[(374,)]\n",
      "[(375,)]\n",
      "[(376,)]\n",
      "[(377,)]\n",
      "[(378,)]\n",
      "[(379,)]\n",
      "[(380,)]\n",
      "[(381,)]\n",
      "[(382,)]\n",
      "[(383,)]\n",
      "[(384,)]\n",
      "[(385,)]\n",
      "[(386,)]\n",
      "[(387,)]\n",
      "[(388,)]\n",
      "[(389,)]\n",
      "[(390,)]\n",
      "[(391,)]\n",
      "[(392,)]\n",
      "[(393,)]\n",
      "[(394,)]\n",
      "[(396,)]\n",
      "[(397,)]\n",
      "[(398,)]\n",
      "[(399,)]\n",
      "[(400,)]\n",
      "[(401,)]\n",
      "[(402,)]\n",
      "[(403,)]\n",
      "[(404,)]\n",
      "[(405,)]\n",
      "[(406,)]\n",
      "[(407,)]\n",
      "[(408,)]\n",
      "[(409,)]\n",
      "[(410,)]\n",
      "[(411,)]\n",
      "[(412,)]\n",
      "[(413,)]\n",
      "[(414,)]\n",
      "[(415,)]\n",
      "[(416,)]\n",
      "[(417,)]\n",
      "[(418,)]\n",
      "[(419,)]\n",
      "[(420,)]\n",
      "[(421,)]\n",
      "[(422,)]\n",
      "[(423,)]\n",
      "[(424,)]\n",
      "[(425,)]\n",
      "[(426,)]\n",
      "[(427,)]\n",
      "[(428,)]\n",
      "[(429,)]\n",
      "[(430,)]\n",
      "[(431,)]\n",
      "[(432,)]\n",
      "[(433,)]\n",
      "[(434,)]\n",
      "[(435,)]\n",
      "[(436,)]\n",
      "[(437,)]\n",
      "[(438,)]\n",
      "[(439,)]\n",
      "[(440,)]\n",
      "[(441,)]\n",
      "[(442,)]\n",
      "[(443,)]\n",
      "[(444,)]\n",
      "[(445,)]\n",
      "[(446,)]\n",
      "[(447,)]\n",
      "[(448,)]\n",
      "[(449,)]\n",
      "[(450,)]\n",
      "[(451,)]\n",
      "[(452,)]\n",
      "[(453,)]\n",
      "[(454,)]\n",
      "[(455,)]\n",
      "[(456,)]\n",
      "[(457,)]\n",
      "[(458,)]\n",
      "[(459,)]\n",
      "[(460,)]\n",
      "[(461,)]\n",
      "[(462,)]\n",
      "[(463,)]\n",
      "[(464,)]\n",
      "[(465,)]\n",
      "[(466,)]\n",
      "[(467,)]\n",
      "[(468,)]\n",
      "[(469,)]\n",
      "[(470,)]\n",
      "[(471,)]\n",
      "[(472,)]\n",
      "[(473,)]\n",
      "[(474,)]\n",
      "[(475,)]\n",
      "[(476,)]\n",
      "[(477,)]\n",
      "[(478,)]\n",
      "[(479,)]\n",
      "[(480,)]\n",
      "[(481,)]\n",
      "[(482,)]\n",
      "[(483,)]\n",
      "[(484,)]\n",
      "[(485,)]\n",
      "[(486,)]\n",
      "[(487,)]\n",
      "[(488,)]\n",
      "[(489,)]\n",
      "[(490,)]\n",
      "[(491,)]\n",
      "[(492,)]\n",
      "[(493,)]\n",
      "[(494,)]\n",
      "[(495,)]\n",
      "[(496,)]\n",
      "[(497,)]\n",
      "[(498,)]\n",
      "[(499,)]\n",
      "[(500,)]\n",
      "[(501,)]\n",
      "[(502,)]\n",
      "[(503,)]\n",
      "[(504,)]\n",
      "[(505,)]\n",
      "[(506,)]\n",
      "[(507,)]\n",
      "[(508,)]\n",
      "[(509,)]\n",
      "[(510,)]\n",
      "[(511,)]\n",
      "[(512,)]\n",
      "[(513,)]\n",
      "[(514,)]\n",
      "[(515,)]\n",
      "[(516,)]\n",
      "[(517,)]\n",
      "[(518,)]\n",
      "[(519,)]\n",
      "[(520,)]\n",
      "[(521,)]\n",
      "[(522,)]\n",
      "[(523,)]\n",
      "[(524,)]\n",
      "[(525,)]\n",
      "[(526,)]\n",
      "[(527,)]\n",
      "[(528,)]\n",
      "[(529,)]\n",
      "[(530,)]\n",
      "[(531,)]\n",
      "[(532,)]\n",
      "[(533,)]\n",
      "[(534,)]\n",
      "[(535,)]\n",
      "[(536,)]\n",
      "[(537,)]\n",
      "[(538,)]\n",
      "[(539,)]\n",
      "[(540,)]\n",
      "[(541,)]\n",
      "[(542,)]\n",
      "[(543,)]\n",
      "[(544,)]\n",
      "[(545,)]\n",
      "[(546,)]\n",
      "[(547,)]\n",
      "[(548,)]\n",
      "[(549,)]\n",
      "[(550,)]\n",
      "[(551,)]\n",
      "[(552,)]\n",
      "[(553,)]\n",
      "[(554,)]\n",
      "[(555,)]\n",
      "[(556,)]\n",
      "[(557,)]\n",
      "[(558,)]\n",
      "[(559,)]\n",
      "[(560,)]\n",
      "[(561,)]\n",
      "[(562,)]\n",
      "[(563,)]\n",
      "[(564,)]\n",
      "[(565,)]\n",
      "[(566,)]\n",
      "[(567,)]\n",
      "[(568,)]\n",
      "[(569,)]\n",
      "[(570,)]\n",
      "[(571,)]\n",
      "[(572,)]\n",
      "[(573,)]\n",
      "[(574,)]\n",
      "[(575,)]\n",
      "[(576,)]\n",
      "[(577,)]\n",
      "[(578,)]\n",
      "[(579,)]\n",
      "[(580,)]\n",
      "[(581,)]\n",
      "[(582,)]\n",
      "[(583,)]\n",
      "[(584,)]\n",
      "[(585,)]\n",
      "[(586,)]\n",
      "[(587,)]\n",
      "[(588,)]\n",
      "[(589,)]\n",
      "[(590,)]\n",
      "[(591,)]\n",
      "[(592,)]\n",
      "[(593,)]\n",
      "[(594,)]\n",
      "[(595,)]\n",
      "[(596,)]\n",
      "[(597,)]\n",
      "[(598,)]\n",
      "[(599,)]\n",
      "[(600,)]\n",
      "[(601,)]\n",
      "[(602,)]\n",
      "[(603,)]\n",
      "[(604,)]\n",
      "[(605,)]\n",
      "[(606,)]\n",
      "[(607,)]\n",
      "[(608,)]\n",
      "[(609,)]\n",
      "[(610,)]\n",
      "[(611,)]\n",
      "[(612,)]\n",
      "[(613,)]\n",
      "[(614,)]\n",
      "[(615,)]\n",
      "[(616,)]\n",
      "[(617,)]\n",
      "[(618,)]\n",
      "[(619,)]\n",
      "[(620,)]\n",
      "[(621,)]\n",
      "[(622,)]\n",
      "[(623,)]\n",
      "[(624,)]\n",
      "[(625,)]\n",
      "[(626,)]\n",
      "[(627,)]\n",
      "[(628,)]\n",
      "[(629,)]\n",
      "[(630,)]\n",
      "[(631,)]\n",
      "[(632,)]\n",
      "[(633,)]\n",
      "[(634,)]\n",
      "[(635,)]\n",
      "[(636,)]\n",
      "[(637,)]\n",
      "[(638,)]\n",
      "[(639,)]\n",
      "[(640,)]\n",
      "[(641,)]\n",
      "[(642,)]\n",
      "[(643,)]\n",
      "[(644,)]\n",
      "[(645,)]\n",
      "[(646,)]\n",
      "[(647,)]\n",
      "[(648,)]\n",
      "[(649,)]\n",
      "[(650,)]\n",
      "[(651,)]\n",
      "[(652,)]\n",
      "[(653,)]\n",
      "[(654,)]\n",
      "[(655,)]\n",
      "[(656,)]\n",
      "[(657,)]\n",
      "[(658,)]\n",
      "[(659,)]\n",
      "[(660,)]\n",
      "[(661,)]\n",
      "[(662,)]\n",
      "[(663,)]\n",
      "[(664,)]\n",
      "[(665,)]\n",
      "[(666,)]\n",
      "[(667,)]\n",
      "[(668,)]\n",
      "[(669,)]\n",
      "[(670,)]\n",
      "[(671,)]\n",
      "[(672,)]\n",
      "[(673,)]\n",
      "[(674,)]\n",
      "[(675,)]\n",
      "[(676,)]\n",
      "[(677,)]\n",
      "[(678,)]\n",
      "[(679,)]\n",
      "[(680,)]\n",
      "[(681,)]\n",
      "[(682,)]\n",
      "[(683,)]\n",
      "[(684,)]\n",
      "[(685,)]\n",
      "[(686,)]\n",
      "[(687,)]\n",
      "[(688,)]\n",
      "[(689,)]\n",
      "[(690,)]\n",
      "[(691,)]\n",
      "[(692,)]\n",
      "[(693,)]\n",
      "[(694,)]\n",
      "[(695,)]\n",
      "[(696,)]\n",
      "[(697,)]\n",
      "[(698,)]\n",
      "[(699,)]\n",
      "[(700,)]\n",
      "[(701,)]\n",
      "[(702,)]\n",
      "[(703,)]\n",
      "[(704,)]\n",
      "[(705,)]\n",
      "[(706,)]\n",
      "[(707,)]\n",
      "[(708,)]\n",
      "[(709,)]\n",
      "[(710,)]\n",
      "[(711,)]\n",
      "[(712,)]\n",
      "[(713,)]\n",
      "[(714,)]\n",
      "[(715,)]\n",
      "[(716,)]\n",
      "[(717,)]\n",
      "[(718,)]\n",
      "[(719,)]\n",
      "[(720,)]\n",
      "[(721,)]\n",
      "[(722,)]\n",
      "[(723,)]\n",
      "[(724,)]\n",
      "[(725,)]\n",
      "[(726,)]\n",
      "[(727,)]\n",
      "[(728,)]\n",
      "[(729,)]\n",
      "[(730,)]\n",
      "[(731,)]\n",
      "[(732,)]\n",
      "[(733,)]\n",
      "[(734,)]\n",
      "[(735,)]\n",
      "[(736,)]\n",
      "[(737,)]\n",
      "[(738,)]\n",
      "[(739,)]\n",
      "[(740,)]\n",
      "[(741,)]\n",
      "[(742,)]\n",
      "[(743,)]\n",
      "[(744,)]\n",
      "[(745,)]\n",
      "[(746,)]\n",
      "[(747,)]\n",
      "[(748,)]\n",
      "[(749,)]\n",
      "[(750,)]\n",
      "[(751,)]\n",
      "[(752,)]\n",
      "[(753,)]\n",
      "[(754,)]\n",
      "[(755,)]\n",
      "[(756,)]\n",
      "[(757,)]\n",
      "[(758,)]\n",
      "[(759,)]\n",
      "[(760,)]\n",
      "[(761,)]\n",
      "[(762,)]\n",
      "[(763,)]\n",
      "[(764,)]\n",
      "[(765,)]\n",
      "[(766,)]\n",
      "[(767,)]\n",
      "[(768,)]\n",
      "[(769,)]\n",
      "[(770,)]\n",
      "[(771,)]\n",
      "[(772,)]\n",
      "[(773,)]\n",
      "[(774,)]\n",
      "[(775,)]\n",
      "[(776,)]\n",
      "[(777,)]\n",
      "[(778,)]\n",
      "[(779,)]\n",
      "[(780,)]\n",
      "[(781,)]\n",
      "[(782,)]\n",
      "[(783,)]\n",
      "[(784,)]\n",
      "[(785,)]\n",
      "[(786,)]\n",
      "[(787,)]\n",
      "[(788,)]\n",
      "[(789,)]\n",
      "[(790,)]\n",
      "[(791,)]\n",
      "[(792,)]\n",
      "[(793,)]\n",
      "[(794,)]\n",
      "[(795,)]\n",
      "[(796,)]\n",
      "[(797,)]\n",
      "[(798,)]\n",
      "[(799,)]\n",
      "[(800,)]\n",
      "[(801,)]\n",
      "[(802,)]\n",
      "[(803,)]\n",
      "[(804,)]\n",
      "[(805,)]\n",
      "[(806,)]\n",
      "[(807,)]\n",
      "[(808,)]\n",
      "[(809,)]\n",
      "[(810,)]\n",
      "[(811,)]\n",
      "[(812,)]\n",
      "[(813,)]\n",
      "[(814,)]\n",
      "[(815,)]\n",
      "[(816,)]\n",
      "[(817,)]\n",
      "[(818,)]\n",
      "[(819,)]\n",
      "[(820,)]\n",
      "[(821,)]\n",
      "[(822,)]\n",
      "[(823,)]\n",
      "[(824,)]\n",
      "[(825,)]\n",
      "[(826,)]\n",
      "[(827,)]\n",
      "[(828,)]\n",
      "[(829,)]\n",
      "[(830,)]\n",
      "[(831,)]\n",
      "[(832,)]\n",
      "[(833,)]\n",
      "[(834,)]\n",
      "[(835,)]\n",
      "[(836,)]\n",
      "[(837,)]\n",
      "[(838,)]\n",
      "[(839,)]\n",
      "[(840,)]\n",
      "[(841,)]\n",
      "[(842,)]\n",
      "[(843,)]\n",
      "[(844,)]\n",
      "[(845,)]\n",
      "[(846,)]\n",
      "[(847,)]\n",
      "[(848,)]\n",
      "[(849,)]\n",
      "[(850,)]\n",
      "[(851,)]\n",
      "[(852,)]\n",
      "[(853,)]\n",
      "[(854,)]\n",
      "[(855,)]\n",
      "[(856,)]\n",
      "[(857,)]\n",
      "[(858,)]\n",
      "[(859,)]\n",
      "[(860,)]\n",
      "[(861,)]\n",
      "[(862,)]\n",
      "[(863,)]\n",
      "[(864,)]\n",
      "[(865,)]\n",
      "[(866,)]\n",
      "[(867,)]\n",
      "[(868,)]\n",
      "[(870,)]\n",
      "[(871,)]\n",
      "[(872,)]\n",
      "[(873,)]\n",
      "[(874,)]\n",
      "[(875,)]\n",
      "[(876,)]\n",
      "[(877,)]\n",
      "[(878,)]\n",
      "[(879,)]\n",
      "[(880,)]\n",
      "[(881,)]\n",
      "[(882,)]\n",
      "[(883,)]\n",
      "[(884,)]\n",
      "[(885,)]\n",
      "[(886,)]\n",
      "[(887,)]\n",
      "[(888,)]\n",
      "[(889,)]\n",
      "[(890,)]\n",
      "[(891,)]\n",
      "[(892,)]\n",
      "[(893,)]\n",
      "[(894,)]\n",
      "[(895,)]\n",
      "[(896,)]\n",
      "[(897,)]\n",
      "[(898,)]\n",
      "[(899,)]\n",
      "[(900,)]\n",
      "[(901,)]\n",
      "[(902,)]\n",
      "[(903,)]\n",
      "[(904,)]\n",
      "[(905,)]\n",
      "[(906,)]\n",
      "[(907,)]\n",
      "[(908,)]\n",
      "[(909,)]\n",
      "[(910,)]\n",
      "[(911,)]\n",
      "[(912,)]\n",
      "[(913,)]\n",
      "[(914,)]\n",
      "[(915,)]\n",
      "[(916,)]\n",
      "[(917,)]\n",
      "[(918,)]\n",
      "[(919,)]\n",
      "[(920,)]\n",
      "[(921,)]\n",
      "[(922,)]\n",
      "[(923,)]\n",
      "[(924,)]\n",
      "[(925,)]\n",
      "[(926,)]\n",
      "[(927,)]\n",
      "[(928,)]\n",
      "[(929,)]\n",
      "[(930,)]\n",
      "[(931,)]\n",
      "[(932,)]\n",
      "[(933,)]\n",
      "[(934,)]\n",
      "[(935,)]\n",
      "[(936,)]\n",
      "[(937,)]\n",
      "[(938,)]\n",
      "[(939,)]\n",
      "[(940,)]\n",
      "[(941,)]\n",
      "[(942,)]\n",
      "[(943,)]\n",
      "[(944,)]\n",
      "[(945,)]\n",
      "[(946,)]\n",
      "[(947,)]\n",
      "[(948,)]\n",
      "[(949,)]\n",
      "[(950,)]\n",
      "[(951,)]\n",
      "[(952,)]\n",
      "[(953,)]\n",
      "[(954,)]\n",
      "[(955,)]\n",
      "[(956,)]\n",
      "[(957,)]\n",
      "[(958,)]\n",
      "[(959,)]\n",
      "[(960,)]\n",
      "[(961,)]\n",
      "[(962,)]\n",
      "[(963,)]\n",
      "[(964,)]\n",
      "[(965,)]\n",
      "[(966,)]\n",
      "[(967,)]\n",
      "[(968,)]\n",
      "[(969,)]\n",
      "[(970,)]\n",
      "[(971,)]\n",
      "[(972,)]\n",
      "[(973,)]\n",
      "[(974,)]\n",
      "[(975,)]\n",
      "[(976,)]\n",
      "[(977,)]\n",
      "[(978,)]\n",
      "[(979,)]\n",
      "[(980,)]\n",
      "[(981,)]\n",
      "[(982,)]\n",
      "[(983,)]\n",
      "[(984,)]\n",
      "[(985,)]\n",
      "[(986,)]\n",
      "[(987,)]\n",
      "[(988,)]\n",
      "[(989,)]\n",
      "[(990,)]\n",
      "[(991,)]\n",
      "[(992,)]\n",
      "[(993,)]\n",
      "[(994,)]\n",
      "[(995,)]\n",
      "[(996,)]\n",
      "[(997,)]\n",
      "[(998,)]\n",
      "[(999,)]\n",
      "[(1000,)]\n",
      "[(1001,)]\n",
      "[(1002,)]\n",
      "[(1003,)]\n",
      "[(1004,)]\n",
      "[(1005,)]\n",
      "[(1006,)]\n",
      "[(1007,)]\n",
      "[(1008,)]\n",
      "[(1009,)]\n",
      "[(1010,)]\n",
      "[(1011,)]\n",
      "[(1012,)]\n",
      "[(1013,)]\n",
      "[(1014,)]\n",
      "[(1015,)]\n",
      "[(1016,)]\n",
      "[(1017,)]\n",
      "[(1018,)]\n",
      "[(1019,)]\n",
      "[(1020,)]\n",
      "[(1021,)]\n",
      "[(1022,)]\n",
      "[(1023,)]\n",
      "[(1024,)]\n",
      "[(1025,)]\n",
      "[(1026,)]\n",
      "[(1027,)]\n",
      "[(1028,)]\n",
      "[(1029,)]\n",
      "[(1030,)]\n",
      "[(1031,)]\n",
      "[(1032,)]\n",
      "[(1033,)]\n",
      "[(1034,)]\n",
      "[(1035,)]\n",
      "[(1036,)]\n",
      "[(1037,)]\n",
      "[(1038,)]\n",
      "[(1039,)]\n",
      "[(1040,)]\n",
      "[(1041,)]\n",
      "[(1042,)]\n",
      "[(1043,)]\n",
      "[(1044,)]\n",
      "[(1045,)]\n",
      "[(1046,)]\n",
      "[(1047,)]\n",
      "[(1048,)]\n",
      "[(1049,)]\n",
      "[(1050,)]\n",
      "[(1051,)]\n",
      "[(1052,)]\n",
      "[(1053,)]\n",
      "[(1054,)]\n",
      "[(1055,)]\n",
      "[(1056,)]\n",
      "[(1057,)]\n",
      "[(1058,)]\n",
      "[(1059,)]\n",
      "[(1060,)]\n",
      "[(1061,)]\n",
      "[(1062,)]\n",
      "[(1063,)]\n",
      "[(1064,)]\n",
      "[(1065,)]\n",
      "[(1066,)]\n",
      "[(1067,)]\n",
      "[(1068,)]\n",
      "[(1069,)]\n",
      "[(1070,)]\n",
      "[(1071,)]\n",
      "[(1072,)]\n",
      "[(1073,)]\n",
      "[(1074,)]\n",
      "[(1075,)]\n",
      "[(1076,)]\n",
      "[(1077,)]\n",
      "[(1078,)]\n",
      "[(1079,)]\n",
      "[(1080,)]\n",
      "[(1081,)]\n",
      "[(1082,)]\n",
      "[(1083,)]\n",
      "[(1084,)]\n",
      "[(1085,)]\n",
      "[(1086,)]\n",
      "[(1087,)]\n",
      "[(1088,)]\n",
      "[(1089,)]\n",
      "[(1090,)]\n",
      "[(1091,)]\n",
      "[(1092,)]\n",
      "[(1093,)]\n",
      "[(1094,)]\n",
      "[(1095,)]\n",
      "[(1096,)]\n",
      "[(1097,)]\n",
      "[(1098,)]\n",
      "[(1099,)]\n",
      "[(1100,)]\n",
      "[(1101,)]\n",
      "[(1102,)]\n",
      "[(1103,)]\n",
      "[(1104,)]\n",
      "[(1105,)]\n",
      "[(1106,)]\n",
      "[(1107,)]\n",
      "[(1108,)]\n",
      "[(1109,)]\n",
      "[(1110,)]\n",
      "[(1111,)]\n",
      "[(1112,)]\n",
      "[(1113,)]\n",
      "[(1114,)]\n",
      "[(1115,)]\n",
      "[(1116,)]\n",
      "[(1117,)]\n",
      "[(1118,)]\n",
      "[(1119,)]\n",
      "[(1120,)]\n",
      "[(1121,)]\n",
      "[(1122,)]\n",
      "[(1123,)]\n",
      "[(1124,)]\n",
      "[(1125,)]\n",
      "[(1126,)]\n",
      "[(1127,)]\n",
      "[(1128,)]\n",
      "[(1129,)]\n",
      "[(1130,)]\n",
      "[(1131,)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rxn_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "temperature",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "replicate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reaction_time",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "probe_concentration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "probe",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "buffer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "construct",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "done_by",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "treated",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sequencing_run",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fq_dir",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fmod_runs",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2eb2b278-ca2a-4826-bc02-b344192afd56",
       "rows": [],
       "shape": {
        "columns": 15,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_group</th>\n",
       "      <th>temperature</th>\n",
       "      <th>replicate</th>\n",
       "      <th>reaction_time</th>\n",
       "      <th>probe_concentration</th>\n",
       "      <th>probe</th>\n",
       "      <th>buffer</th>\n",
       "      <th>construct</th>\n",
       "      <th>RT</th>\n",
       "      <th>done_by</th>\n",
       "      <th>treated</th>\n",
       "      <th>sequencing_run</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>fq_dir</th>\n",
       "      <th>fmod_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rxn_group, temperature, replicate, reaction_time, probe_concentration, probe, buffer, construct, RT, done_by, treated, sequencing_run, sample_name, fq_dir, fmod_runs]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrt_only = samples[(samples['RT'] == 'MRT') | (samples['RT'] == 'MRTpH9')]\n",
    "# drop nan values \n",
    "mrt_only = mrt_only.dropna(subset=['fmod_runs'])\n",
    "\n",
    "for i, row in mrt_only.iterrows():\n",
    "    fmod_dir = row['fmod_runs']\n",
    "    sample_name = row['sample_name']\n",
    "\n",
    "    # get text inside single quote '\n",
    "    if \"'\" in fmod_dir:\n",
    "        fmod_dir = fmod_dir.split(\"'\")[1]\n",
    "    #print(fmod_dir)\n",
    "    #print(sample_name)\n",
    "    if row['sequencing_run'] == 23:\n",
    "        run0420 = True\n",
    "    else:\n",
    "        run0420 = None\n",
    "    try:\n",
    "        run_datetime, run_args, version, use_untreated_calc, r1_file, sample_check, s_id, fmod_calc_id, profile_txt, profile_txtga = construct_fmod_calc_run(sample_name, fmod_dir, db_file, run0420)\n",
    "    except:\n",
    "        print('---------------------------------------------')\n",
    "        print(sample_name)\n",
    "        traceback.print_exc()\n",
    "        print('---------------------------------------------')\n",
    "        continue\n",
    "\n",
    "    if sample_check:\n",
    "        fmod_vals_df = construct_fmod_vals(profile_txt, db_file, s_id, fmod_calc_id, use_untreated_calc)\n",
    "        if profile_txtga is not None:\n",
    "            fmod_vals_df_ga = construct_fmod_vals(profile_txtga, db_file, s_id, fmod_calc_id, use_untreated_calc)\n",
    "            fmod_vals_df_ga['valtype'] = 'GAmodrate'\n",
    "            fmod_vals_df = pd.concat([fmod_vals_df, fmod_vals_df_ga])\n",
    "        \n",
    "        # Append fmod_calc_run fmod_vals to db\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        c = conn.cursor()\n",
    "        c.execute('INSERT INTO fmod_calc_runs (id, s_id, software_name, software_version, run_args, output_dir) VALUES (?, ?, ?, ?, ?, ?)', (fmod_calc_id, s_id, 'shapemapper', version, run_args, r1_file))\n",
    "        fmod_vals_df.to_sql('fmod_vals', conn, if_exists='append', index=False)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        # Processed done, drop row\n",
    "        mrt_only = mrt_only.drop(index=i)\n",
    "    else:\n",
    "        print(fmod_dir, r1_file, sample_name)\n",
    "        print('Sample name does not match R1 file, skipping...')\n",
    "        continue\n",
    "    \n",
    "mrt_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrt_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_spats(log_file, config_file, sample_name):\n",
    "    \"\"\"\n",
    "    Extracts information from a spats directory.\n",
    "\n",
    "    Parameters:\n",
    "        log_file (str): Path to the ShapeMapper log file.\n",
    "        sample_name (str): Name of the sample to check against the R1 file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains the following elements:\n",
    "            - run_datetime (str): The datetime when the ShapeMapper run started.\n",
    "            - version (str): The version of ShapeMapper used.\n",
    "            - r1_file (str): The R1 file used in the run.\n",
    "            - untreated (int): Indicates if the sample was untreated (1 if untreated, 0 otherwise).\n",
    "            - denatured (int): Indicates if the sample was denatured (1 if denatured, 0 otherwise).\n",
    "            - sample_check (bool): Indicates if the sample name matches the R1 file.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(log_file) as f:\n",
    "        log_lines = f.readlines()\n",
    "    \n",
    "    with open(config_file) as f:\n",
    "        config_lines = f.readlines()\n",
    "\n",
    "    # find all lines containing \" : run \" and get index of most recent one\n",
    "    detect_spats_runs = [i for i, line in enumerate(log_lines) if ' : run' in line]\n",
    "    assert len(detect_spats_runs) > 0, 'No spats runs detected in log file'\n",
    "\n",
    "    most_recent_run = detect_spats_runs[-1]\n",
    "    log_lines = log_lines[most_recent_run:]\n",
    "\n",
    "    # check spats success\n",
    "    #TODO\n",
    "\n",
    "    #print(log_file)\n",
    "    # extract date from:  \"2022/11/26 11:56 : run, 172.31s\"\n",
    "    run_datetime = log_lines[0].split(' : run')[0]\n",
    "    version = 'v2.0.5'\n",
    "    \n",
    "    # extract run args\n",
    "    run_args = [line for i, line in enumerate(log_lines) if not line.startswith('#')]\n",
    "    run_args = '\\n'.join(run_args)\n",
    "    \n",
    "    # extract R1 file\n",
    "    r1_lines = [line for line in config_lines if 'r1' in line]\n",
    "    assert (len(r1_lines) == 1), 'R1 line not found in config file'\n",
    "\n",
    "    r1_file = r1_lines[0].split('=')[-1]\n",
    "    r1_file = r1_file.replace(' ', '').rstrip()\n",
    "    assert (r1_file is not None) or (r1_file == ''), 'R1 file not found in run_args'\n",
    "    \n",
    "    # confirm sample_name matches r1_file\n",
    "    if r1_file.endswith('.fastq.gz'):\n",
    "        r1_file_check = r1_file[:-9]\n",
    "    elif r1_file.endswith('.fastq'):\n",
    "        r1_file_check = r1_file[:-6]\n",
    "    else:\n",
    "        r1_file_check = r1_file\n",
    "    if sample_name.endswith('.fastq.gz'):\n",
    "        sample_name_check = sample_name[:-9]\n",
    "    elif sample_name.endswith('.fastq'):\n",
    "        sample_name_check = sample_name[:-6]\n",
    "    else:\n",
    "        sample_name_check = sample_name\n",
    "    if r1_file.startswith('./'):\n",
    "        r1_file_check = r1_file_check[2:]\n",
    "\n",
    "    sample_check = (sample_name_check == r1_file_check)\n",
    "    \n",
    "    return run_datetime, run_args, version, r1_file, sample_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_fmod_calc_run_spats(sample_name, fmod_dir, db_file):\n",
    "\n",
    "    \n",
    "    log_file = glob.glob(f'/projects/b1044/Computational_Output/EKC/{fmod_dir}/**/spats.log', recursive = True)[0]\n",
    "    config_file = glob.glob(f'/projects/b1044/Computational_Output/EKC/{fmod_dir}/**/spats.config', recursive = True)[0]\n",
    "    run_datetime, run_args, version, r1_file, sample_check = extract_info_from_spats(log_file, config_file, sample_name)\n",
    "    s_id = fetch_s_id(db_file, sample_name)\n",
    "\n",
    "    # get potential fmod_calc id but do not add until fmod vals are good\n",
    "\n",
    "    # Tentative fmod_calc id (pending fmod_vals check)\n",
    "    fmod_calc_id = get_max_id(db_file, 'fmod_calc_runs', 'id')\n",
    "\n",
    "    profile_txt = glob.glob(f'/projects/b1044/Computational_Output/EKC/{fmod_dir}/**/*.csv', recursive=True)\n",
    "    # exclude reads.csv\n",
    "    profile_txt = [x for x in profile_txt if 'reads' not in x]\n",
    "    \n",
    "    # choose profile with \"reanalyzed\"\n",
    "    if len(profile_txt) > 1:\n",
    "        profile_txt = [x for x in profile_txt if 'reanalyzed' in x]\n",
    "        #print(fmod_dir, profile_txt)\n",
    "    assert len(profile_txt) == 1, 'Multiple or no profile.txt files found'\n",
    "    profile_txt = profile_txt[0]\n",
    "\n",
    "    return run_datetime, run_args, version, r1_file, sample_check, s_id, fmod_calc_id, profile_txt\n",
    "\n",
    "def construct_fmod_vals_spats(profile_txt, db_file, s_id, fmod_calc_id):\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(profile_txt)\n",
    "    read_depth = df.iloc[0, 3]#['f+']\n",
    "    df = df.iloc[1:, :]\n",
    "\n",
    "    seq_from_profile = ''.join(df['nt'].values)\n",
    "    dict_convertTU = {'T': 'U', 't': 'u'}\n",
    "    seq_from_profile = ''.join([dict_convertTU.get(base, base) for base in seq_from_profile])\n",
    "    \n",
    "    construct_seq = fetch_construct_seq(db_file, s_id)\n",
    "    assert construct_seq.upper() == seq_from_profile.upper(), 'Construct sequence does not match spats out.csv sequence'\n",
    "\n",
    "    nt_ids, nt_seq = fetch_nt_ids(db_file, s_id)\n",
    "    assert nt_seq.upper() == seq_from_profile.upper(), 'Nt sequence does not match profile.txt sequence'\n",
    "\n",
    "    rxn_id, rxn_treated = fetch_rxn_id(db_file, s_id)\n",
    "\n",
    "    fmod_vals_df = pd.DataFrame({'nt_id': nt_ids, 'fmod_calc_run_id': fmod_calc_id, 'fmod_val': df['beta'], 'valtype': 'beta', 'read_depth': read_depth, 'rxn_id': rxn_id})\n",
    "    return fmod_vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmod_calc_runs_2/000000000189\n",
      "006-EKC-fourUnew-WT-II-37C-dms-stop-90_S6_L001_R1_001.fastq.gz\n",
      "[(6,)]\n"
     ]
    }
   ],
   "source": [
    "samples = pd.read_csv('/projects/b1044/Computational_Output/EKC/EKC.01_SHAPE_standardization/EKC.01.060.developing_DB_input/samples_import.csv')\n",
    "\n",
    "i = 5\n",
    "# check if sample_name column has not repeats\n",
    "fmod_dir = samples[samples['RT'] == 'SSIII']['fmod_runs'].values[i]\n",
    "sample_name = samples[samples['RT'] == 'SSIII']['sample_name'].values[i]\n",
    "\n",
    "# get text inside single quote '\n",
    "if \"'\" in fmod_dir:\n",
    "    fmod_dir = fmod_dir.split(\"'\")[1]\n",
    "print(fmod_dir)\n",
    "print(sample_name)\n",
    "db_file = '/projects/b1044/Computational_Output/EKC/EKC.01_SHAPE_standardization/EKC.01.060.developing_DB_input/new.db'\n",
    "\n",
    "try:\n",
    "    run_datetime, run_args, version, r1_file, sample_check, s_id, fmod_calc_id, profile_txt = construct_fmod_calc_run_spats(sample_name, fmod_dir, db_file)\n",
    "except:\n",
    "     print('Error in log file, skipping...')\n",
    "if sample_check:\n",
    "     fmod_vals_df = construct_fmod_vals_spats(profile_txt, db_file, s_id, fmod_calc_id)\n",
    "else:\n",
    "     print('Sample name does not match R1 file, skipping...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,)]\n",
      "[(2,)]\n",
      "[(3,)]\n",
      "[(4,)]\n",
      "[(5,)]\n",
      "[(6,)]\n",
      "[(7,)]\n",
      "[(8,)]\n",
      "[(9,)]\n",
      "[(10,)]\n",
      "[(11,)]\n",
      "[(12,)]\n",
      "[(13,)]\n",
      "[(14,)]\n",
      "[(15,)]\n",
      "[(16,)]\n",
      "[(41,)]\n",
      "[(42,)]\n",
      "[(43,)]\n",
      "[(44,)]\n",
      "[(45,)]\n",
      "[(46,)]\n",
      "[(47,)]\n",
      "[(48,)]\n",
      "[(49,)]\n",
      "[(50,)]\n",
      "[(51,)]\n",
      "[(52,)]\n",
      "[(53,)]\n",
      "[(54,)]\n",
      "[(55,)]\n",
      "[(56,)]\n",
      "[(81,)]\n",
      "[(82,)]\n",
      "[(83,)]\n",
      "[(84,)]\n",
      "[(85,)]\n",
      "[(86,)]\n",
      "[(87,)]\n",
      "[(88,)]\n",
      "[(89,)]\n",
      "[(90,)]\n",
      "[(91,)]\n",
      "[(92,)]\n",
      "[(93,)]\n",
      "[(94,)]\n",
      "[(95,)]\n",
      "[(96,)]\n",
      "[(97,)]\n",
      "[(98,)]\n",
      "[(99,)]\n",
      "[(100,)]\n",
      "[(101,)]\n",
      "[(102,)]\n",
      "[(103,)]\n",
      "[(104,)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rxn_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "temperature",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "replicate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reaction_time",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "probe_concentration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "probe",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "buffer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "construct",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "done_by",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "treated",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sequencing_run",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fq_dir",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fmod_runs",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ffa99638-f5e7-45c8-99ed-dcae01baa522",
       "rows": [],
       "shape": {
        "columns": 15,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rxn_group</th>\n",
       "      <th>temperature</th>\n",
       "      <th>replicate</th>\n",
       "      <th>reaction_time</th>\n",
       "      <th>probe_concentration</th>\n",
       "      <th>probe</th>\n",
       "      <th>buffer</th>\n",
       "      <th>construct</th>\n",
       "      <th>RT</th>\n",
       "      <th>done_by</th>\n",
       "      <th>treated</th>\n",
       "      <th>sequencing_run</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>fq_dir</th>\n",
       "      <th>fmod_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rxn_group, temperature, replicate, reaction_time, probe_concentration, probe, buffer, construct, RT, done_by, treated, sequencing_run, sample_name, fq_dir, fmod_runs]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssiii_only = samples[~((samples['RT'] == 'MRT') | (samples['RT'] == 'MRTpH9'))]\n",
    "# drop nan values \n",
    "ssiii_only = ssiii_only.dropna(subset=['fmod_runs'])\n",
    "\n",
    "for i, row in ssiii_only.iterrows():\n",
    "    fmod_dir = row['fmod_runs']\n",
    "    sample_name = row['sample_name']\n",
    "\n",
    "    # get text inside single quote '\n",
    "    if \"'\" in fmod_dir:\n",
    "        fmod_dir = fmod_dir.split(\"'\")[1]\n",
    "    #print(fmod_dir)\n",
    "    #print(sample_name)\n",
    "    \n",
    "    try:\n",
    "        run_datetime, run_args, version, r1_file, sample_check, s_id, fmod_calc_id, profile_txt = construct_fmod_calc_run_spats(sample_name, fmod_dir, db_file)\n",
    "    except:\n",
    "        print('---------------------------------------------')\n",
    "        print(sample_name)\n",
    "        traceback.print_exc()\n",
    "        print('---------------------------------------------')\n",
    "        continue\n",
    "\n",
    "    if sample_check:\n",
    "        fmod_vals_df = construct_fmod_vals_spats(profile_txt, db_file, s_id, fmod_calc_id)\n",
    "        \n",
    "        # Append fmod_calc_run fmod_vals to db\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        c = conn.cursor()\n",
    "        c.execute('INSERT INTO fmod_calc_runs (id, s_id, software_name, software_version, run_args, output_dir) VALUES (?, ?, ?, ?, ?, ?)', (fmod_calc_id, s_id, 'shapemapper', version, run_args, r1_file))\n",
    "        fmod_vals_df.to_sql('fmod_vals', conn, if_exists='append', index=False)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        # Processed done, drop row\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(fmod_dir, r1_file, sample_name)\n",
    "        print('Sample name does not match R1 file, skipping...')\n",
    "        continue\n",
    "    \n",
    "    # simulate processed by dropping row\n",
    "    ssiii_only = ssiii_only.drop(index=i)\n",
    "    \n",
    "ssiii_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# mv from src to dest\n",
    "\n",
    "def move_directory_unix(src_dir, dest_dir):\n",
    "    # mv automatically handles directories and their contents without the need for -r\n",
    "    subprocess.run(['mv', src_dir, dest_dir], check=True)\n",
    "    print(f\"Moved {src_dir} to {dest_dir} using mv command\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    move_directory_unix(row['src_dir'], row['dest_dir'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nupack",
   "language": "python",
   "name": "nupack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
